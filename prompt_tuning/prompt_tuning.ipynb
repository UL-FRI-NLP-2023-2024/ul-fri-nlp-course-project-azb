{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: langchain in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 2)) (0.1.16)\n",
      "Requirement already satisfied: python-dotenv in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: openai in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 4)) (1.23.6)\n",
      "Requirement already satisfied: openpyxl in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: jsonlines in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 6)) (4.0.0)\n",
      "Requirement already satisfied: matplotlib in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 7)) (3.8.4)\n",
      "Requirement already satisfied: networkx in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 8)) (3.3)\n",
      "Requirement already satisfied: accelerate in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 9)) (0.30.0.dev0)\n",
      "Requirement already satisfied: bitsandbytes in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 10)) (0.43.1)\n",
      "Requirement already satisfied: huggingface_hub in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 11)) (0.22.2)\n",
      "Requirement already satisfied: setuptools in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 13)) (69.5.1)\n",
      "Requirement already satisfied: ipywidgets in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 14)) (8.1.2)\n",
      "Requirement already satisfied: datasets in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 15)) (2.19.0)\n",
      "Requirement already satisfied: evaluate in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 16)) (0.4.2)\n",
      "Requirement already satisfied: scikit-learn in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 17)) (1.4.2)\n",
      "Requirement already satisfied: sentence-transformers in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from -r requirements.txt (line 18)) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from pandas->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from pandas->-r requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from pandas->-r requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 2)) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 2)) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 2)) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 2)) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 2)) (0.0.34)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 2)) (0.1.46)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 2)) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 2)) (0.1.51)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 2)) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from langchain->-r requirements.txt (line 2)) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from openai->-r requirements.txt (line 4)) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from openai->-r requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from openai->-r requirements.txt (line 4)) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from openai->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from openai->-r requirements.txt (line 4)) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from openai->-r requirements.txt (line 4)) (4.11.0)\n",
      "Requirement already satisfied: et-xmlfile in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from openpyxl->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from jsonlines->-r requirements.txt (line 6)) (23.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from matplotlib->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from matplotlib->-r requirements.txt (line 7)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from matplotlib->-r requirements.txt (line 7)) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from matplotlib->-r requirements.txt (line 7)) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from matplotlib->-r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: psutil in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from accelerate->-r requirements.txt (line 9)) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from accelerate->-r requirements.txt (line 9)) (2.3.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from accelerate->-r requirements.txt (line 9)) (0.4.3)\n",
      "Requirement already satisfied: filelock in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from huggingface_hub->-r requirements.txt (line 11)) (3.13.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from huggingface_hub->-r requirements.txt (line 11)) (2024.3.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 14)) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 14)) (8.24.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 14)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 14)) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 14)) (3.0.10)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from datasets->-r requirements.txt (line 15)) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from datasets->-r requirements.txt (line 15)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from datasets->-r requirements.txt (line 15)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from datasets->-r requirements.txt (line 15)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from datasets->-r requirements.txt (line 15)) (0.70.16)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 17)) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 17)) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 17)) (3.5.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from sentence-transformers->-r requirements.txt (line 18)) (4.41.0.dev0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 4)) (3.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 2)) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: certifi in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: decorator in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 14)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 14)) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 14)) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 14)) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 14)) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 14)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 14)) (4.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain->-r requirements.txt (line 2)) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 2)) (3.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 2)) (2.18.2)\n",
      "Requirement already satisfied: six>=1.5 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 2)) (3.0.3)\n",
      "Requirement already satisfied: sympy in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (1.12)\n",
      "Requirement already satisfied: jinja2 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (12.4.127)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->-r requirements.txt (line 18)) (2024.4.16)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->-r requirements.txt (line 18)) (0.19.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 14)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 14)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 14)) (0.2.13)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (2.1.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 14)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 14)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 14)) (0.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"train_dataset\")\n",
    "test_df = pd.read_pickle(\"test_dataset\")\n",
    "val_df = pd.read_pickle(\"val_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_df),\n",
    "    'test': Dataset.from_pandas(test_df),\n",
    "    'unsupervised': Dataset.from_pandas(val_df)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 427\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 92\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 92\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'So regarding part 1 of the question, I think the lady is behind the door!',\n",
       " 'label': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gradio in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (4.28.3)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (5.3.0)\n",
      "Requirement already satisfied: fastapi in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (0.110.2)\n",
      "Requirement already satisfied: ffmpy in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==0.16.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (0.22.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: numpy~=1.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (3.10.1)\n",
      "Requirement already satisfied: packaging in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (10.3.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (2.7.1)\n",
      "Requirement already satisfied: pydub in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (0.4.2)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (2.2.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio) (0.29.0)\n",
      "Requirement already satisfied: fsspec in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio-client==0.16.0->gradio) (2024.3.1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from gradio-client==0.16.0->gradio) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio) (4.21.1)\n",
      "Requirement already satisfied: toolz in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: anyio in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from httpx>=0.24.1->gradio) (4.3.0)\n",
      "Requirement already satisfied: certifi in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: idna in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from httpx>=0.24.1->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.4)\n",
      "Requirement already satisfied: requests in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from fastapi->gradio) (0.37.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentencepiece in /d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install latest bitsandbytes & transformers, accelerate from source\n",
    "%pip install -q -U bitsandbytes\n",
    "# %pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "# %pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "# %pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "%pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n",
    "# Other requirements for the demo\n",
    "%pip install gradio\n",
    "%pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required for a meta-llama/Llama-2-13b-chat-hf\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # This loads the .env file into the environment\n",
    "\n",
    "hf_token = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load the model baffo32/decapoda-research-llama-7b-hf into memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/hpc/home/bi4528/.venv/lib64/python3.11/site-packages/transformers/generation/configuration_utils.py:479: UserWarning: `pad_token_id` should be positive but got -1. This will cause errors when batch generating, if there is padding. Please set `pas_token_id` explicitly by `model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation, and ensure your `input_ids` input does not have negative values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fa7e4ca7634a03a1413e33ee50e019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the model baffo32/decapoda-research-llama-7b-hf into memory\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel    \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizer, StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer, DataCollatorWithPadding\n",
    "import evaluate\n",
    "\n",
    "model_name = \"baffo32/decapoda-research-llama-7b-hf\"\n",
    "adapters_name = 'timdettmers/guanaco-7b'\n",
    "\n",
    "print(f\"Starting to load the model {model_name} into memory\")\n",
    "\n",
    "m = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    #load_in_4bit=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "m = PeftModel.from_pretrained(m, adapters_name)\n",
    "m = m.merge_and_unload()\n",
    "tok = LlamaTokenizer.from_pretrained(model_name)\n",
    "tok.bos_token_id = 1\n",
    "\n",
    "stop_token_ids = [0]\n",
    "\n",
    "tok.pad_token = tok.eos_token\n",
    "tok.pad_token_id = tok.eos_token_id\n",
    "\n",
    "m.config.pad_token_id = tok.pad_token_id\n",
    "\n",
    "print(f\"Successfully loaded the model {model_name} into memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "class CompleteWordCriteria(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, valid_words):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.valid_words = valid_words\n",
    "\n",
    "    def __call__(self, input_ids, scores):\n",
    "        # Decode the last generated token to a word\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        last_word = tokens[-1]\n",
    "        # Decode the entire sequence to check the last whole word\n",
    "        decoded_sequence = self.tokenizer.decode(input_ids[0])\n",
    "        last_generated_word = decoded_sequence.split()[-1]\n",
    "        # Check if the last whole word generated is a valid category word\n",
    "        return last_generated_word in self.valid_words\n",
    "\n",
    "\n",
    "def generate_text(prompt, max_length=2048, max_new_tokens=5):\n",
    "    # Configure the device for model execution\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    m.to(device)\n",
    "\n",
    "    # Encode the input prompt into tensor format\n",
    "    inputs = tok(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Define the stopping criteria\n",
    "    valid_categories = [\"Seminar\", \"Deliberation\", \"Social\", \"UX\", \"Procedure\", \"Imaginative\", \"Other\"]\n",
    "    criteria_list = StoppingCriteriaList([CompleteWordCriteria(tok, valid_categories)])\n",
    "\n",
    "    # Generate text using the model\n",
    "    output_sequences = m.generate(\n",
    "        input_ids=inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        max_length = max_length,\n",
    "        stopping_criteria=criteria_list\n",
    "    )\n",
    "\n",
    "    # Decode the generated ids to text\n",
    "    text = tok.decode(output_sequences[0], skip_special_tokens=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "def BERTEmbbedingsKMeans():\n",
    "\n",
    "    categories = train_df['label'].unique()\n",
    "\n",
    "    representative_texts = []\n",
    "\n",
    "    for category in categories:\n",
    "        # Filter data for the current category\n",
    "        category_data = train_df[train_df['label'] == category]\n",
    "        texts = category_data['text'].tolist()\n",
    "        \n",
    "        # Generate embeddings\n",
    "        embeddings = model.encode(texts, show_progress_bar=True)\n",
    "        \n",
    "        # Perform K-means clustering\n",
    "        n_clusters = 5\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "        cluster_labels = kmeans.fit_predict(embeddings)\n",
    "        \n",
    "        # Add cluster labels back to the DataFrame for the current category\n",
    "        category_data['cluster_label'] = cluster_labels\n",
    "        \n",
    "        # Select representatives from each cluster\n",
    "        for cluster in range(n_clusters):\n",
    "            cluster_data = category_data[category_data['cluster_label'] == cluster]\n",
    "            # Compute distances from the cluster centroids\n",
    "            centroids = kmeans.cluster_centers_[cluster]\n",
    "            distances = cluster_data.apply(lambda x: np.linalg.norm(model.encode([x['text']]) - centroids), axis=1)\n",
    "            chosen_indices = distances.nsmallest(1).index  # Select one representative per cluster\n",
    "            representative_texts.extend(category_data.loc[chosen_indices].to_dict('records'))\n",
    "    return representative_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.cluster.hierarchy import ward, fcluster, dendrogram\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "def BERTEmbeddingsHC():\n",
    "\n",
    "    representative_texts = []\n",
    "\n",
    "    for category in train_df['label'].unique():\n",
    "        # Filter data for the current category and reset index for alignment\n",
    "        category_data = train_df[train_df['label'] == category].reset_index(drop=True)\n",
    "        texts = category_data['text'].tolist()\n",
    "\n",
    "        # Generate embeddings\n",
    "        embeddings = model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "        # Compute the condensed distance matrix for hierarchical clustering\n",
    "        distance_matrix = pdist(embeddings, 'cosine')\n",
    "\n",
    "        # Perform hierarchical clustering\n",
    "        linkage_matrix = ward(distance_matrix)\n",
    "\n",
    "        # Apply clustering to the data\n",
    "        cluster_labels = fcluster(linkage_matrix, t=5, criterion='maxclust')\n",
    "        category_data['cluster_label'] = cluster_labels\n",
    "\n",
    "        # Select representatives from each cluster\n",
    "        for cluster in range(1, 6):  # Clusters are 1-indexed from fcluster\n",
    "            cluster_data = category_data[category_data['cluster_label'] == cluster]\n",
    "            \n",
    "            if not cluster_data.empty:\n",
    "                cluster_indices = cluster_data.index.tolist()\n",
    "                cluster_embeddings = embeddings[cluster_indices]\n",
    "                centroid = np.mean(cluster_embeddings, axis=0)\n",
    "                distances = np.linalg.norm(cluster_embeddings - centroid, axis=1)\n",
    "                min_index = distances.argmin()\n",
    "                representative_texts.append(cluster_data.iloc[min_index].to_dict())\n",
    "    return representative_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def tfidf_KMeans():\n",
    "    \n",
    "    representative_texts = []\n",
    "\n",
    "    for category in train_df['label'].unique():\n",
    "        # Filter data for the current category\n",
    "        category_data = train_df[train_df['label'] == category].copy()\n",
    "\n",
    "        # Generate TF-IDF vectors for texts within this category\n",
    "        tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(category_data['text'])\n",
    "\n",
    "        # Perform K-means clustering\n",
    "        n_clusters = min(7, len(category_data))  # Ensure we don't exceed the number of samples\n",
    "        if n_clusters > 1:  # Proceed only if clustering is possible\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "            cluster_labels = kmeans.fit_predict(tfidf_matrix)\n",
    "\n",
    "            # Add cluster labels back to the category-specific DataFrame\n",
    "            category_data['cluster_label'] = cluster_labels\n",
    "\n",
    "            # Select representative texts from each cluster\n",
    "            for cluster in range(n_clusters):\n",
    "                cluster_data = category_data[category_data['cluster_label'] == cluster]\n",
    "                # Pick the text closest to the cluster center as the representative\n",
    "                if not cluster_data.empty:\n",
    "                    center = kmeans.cluster_centers_[cluster]\n",
    "                    distances = cluster_data.apply(lambda x: np.linalg.norm(\n",
    "                        tfidf_vectorizer.transform([x['text']]).toarray() - center), axis=1)\n",
    "                    min_index = distances.idxmin()\n",
    "                    representative_texts.append(cluster_data.loc[min_index].to_dict())\n",
    "        else:\n",
    "            # If clustering is not possible, take a random sample\n",
    "            representative_texts.append(category_data.sample(n=1).to_dict('records')[0])\n",
    "    return representative_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelToCategory = {\n",
    "    0: 'Seminar',\n",
    "    1: 'Deliberation',\n",
    "    2: 'Social',\n",
    "    3: 'UX',\n",
    "    4: 'Procedure',\n",
    "    5: 'Imaginative',\n",
    "    6: 'Other'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryToLabel = {\n",
    "    'Seminar': 0,\n",
    "    'Deliberation': 1,\n",
    "    'Social': 2,\n",
    "    'UX': 3,\n",
    "    'Procedure': 4,\n",
    "    'Imaginative': 5,\n",
    "    'Other': 6\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17ef236285b44e39417286c583e5ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f0cc6d660d4eca870d825a5530d7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dba61dc5c794f1aa5659035116fd40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98931c7922744064ac3f9a7a9e961a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a5064cfd254fb2915aaf3b918c5d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c242a7c9e86a47dc959a8eb1378a3dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca5c2758f0144449a0a1edcdf7beb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    }
   ],
   "source": [
    "def create_prompt(test_text, representatives):\n",
    "    prompt = \"Classify the text into categories: Seminar, Deliberation, Social, UX, Procedure, Imaginative, Other.\\nHere are some annotated examples:\\n\"\n",
    "    for example in representatives:\n",
    "        prompt += f\"Text: \\'{example['text']}\\' - Category: {labelToCategory[example['label']]}\\n\"\n",
    "    prompt += f\"Text: \\'{test_text}\\' - Category:\"\n",
    "    return prompt\n",
    "\n",
    "# Example use of the prompt with a test text\n",
    "test_text = \"Oooo I have another idea! What if the princess sends the man to the tiger and right out tells her father she did it and wants a trial. Then because he loves her he begs her to choose the door with the young man he picks for her, but she chooses the tiger.\"\n",
    "representative_texts = BERTEmbbedingsKMeans() #BERTEmbeddingsHC(), tfidf_KMeans()\n",
    "prompt = create_prompt(test_text, representative_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the text into categories: Seminar, Deliberation, Social, UX, Procedure, Imaginative, Other.\n",
      "Here are some annotated examples:\n",
      "Text: 'I agree' - Category: Procedure\n",
      "Text: 'I want to believe the tiger was behind the door because the princess was semi-barbaric but she was also filled with despair and jealousy.  The green eyed monster.. gets you every time...so she knows she has lost him, but she doesn't have to let the Lady have him.' - Category: Procedure\n",
      "Text: 'As for the second part, I'm not sure if the King would carry out the same punishment for his daughter as he would the commoners. However, he would definitely think of another way to punish her that would consist of a clever, yet barbaric twist for her to prove her loyalty and worth.' - Category: Procedure\n",
      "Text: 'Hi everyone! I think what happens next is that the princess let her lover marry the woman. The reason why I think she would do that is because she loves the man (as they had made each other the center of each others universe) and she would rather see him alive then feel guilty that she is the reason why he dies (she had nightmares of her lover being killed by the tiger). The king represent determinism and barbarism by having chance dictate one's choice (which he had demonstrated in the arena.)  The princess represented free will and progressivism because she actively went out of her way to know which door held which. I do not think a good lover will put harm's way to their love ones. The princess lost the man regardless of which door she choose but at least she can fulfill her role as a lover to never put harms way in his direction and not let the barbaric nature from her father's bloodline to overcome her moral compass.' - Category: Procedure\n",
      "Text: 'I kind of think that even though she is angry and jealous, she would ultimately save him. ' - Category: Procedure\n",
      "Text: 'Good job ladies. Thank you both.' - Category: Imaginative\n",
      "Text: 'Thanks for hopping on for a little bit! I hope you both have a great rest of this semester!' - Category: Imaginative\n",
      "Text: 'Okay!' - Category: Imaginative\n",
      "Text: 'lol ' - Category: Imaginative\n",
      "Text: 'Goodnight!' - Category: Imaginative\n",
      "Text: 'Yeah I put questions, I'll refresh and try again' - Category: Other\n",
      "Text: 'So I don't know. ' - Category: Other\n",
      "Text: 'Which browser did you use?' - Category: Other\n",
      "Text: 'then click submit' - Category: Other\n",
      "Text: 'Perhaps the top of this page (where we type and send messages) is for planning and the bottom (open white area) is for writing an end to the story? ' - Category: Other\n",
      "Text: 'I think you are correct, Ashley. ' - Category: Seminar\n",
      "Text: 'Did you guys get the final question' - Category: Seminar\n",
      "Text: 'If you would like, we can leave both our answers and your ending. That way we have both options covered. But if you'd rather not that's okay too.' - Category: Seminar\n",
      "Text: 'Also feel free to add anything to them if you would like.' - Category: Seminar\n",
      "Text: 'Yes, I think so. We were discussing if we write it like answers or finish the story? Thoughts?' - Category: Seminar\n",
      "Text: 'SUBMITTED' - Category: UX\n",
      "Text: 'Dr. Austin said have fun with it, and it is fun to ponder what might happen in the story. I think the main reason for setting a time to discuss it at the same time would be to test the collaborative software, using the box below instead of this one. I believe we could all write in it at the same time and see each other typing and change each other's words until we all agree we are done with our assessment. If we are able to do that, we might find there are unexpected positives or negatives to the collaboration process or system that we can only otherwise surmise. As you say, we've all responded to the prompts, so what we say doesn't matter that much, so all we'd need is a few minutes to see how using the box works. So if you want to try meeting, I could do Wednesday any time of day. Just set a time and I'll log on then. Thanks.' - Category: UX\n",
      "Text: 'Do you see what I typed in the box below?' - Category: UX\n",
      "Text: 'I'm also in LIS6303!' - Category: UX\n",
      "Text: 'I just replied to the email, but yes\" I can meet back here tomorrow (Tues. at 8pm). \"See\" you all then!\"' - Category: UX\n",
      "Text: 'Ha ha, maybe!' - Category: Deliberation\n",
      "Text: 'I think I'd find it easier to move on and live if he was still alive.' - Category: Deliberation\n",
      "Text: 'I mean there are other guys out there after all.' - Category: Deliberation\n",
      "Text: 'I agree with that so much! ' - Category: Deliberation\n",
      "Text: 'Do you think that the king would be tempted to do the same thing she did, though, and find out which door was which?' - Category: Deliberation\n",
      "Text: 's' - Category: Social\n",
      "Text: 'ha\"' - Category: Social\n",
      "Text: 'uwgyeu' - Category: Social\n",
      "Text: 'darla' - Category: Social\n",
      "Text: 'mor' - Category: Social\n",
      "Text: 'Oooo I have another idea! What if the princess sends the man to the tiger and right out tells her father she did it and wants a trial. Then because he loves her he begs her to choose the door with the young man he picks for her, but she chooses the tiger.' - Category:\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: Classify the text into categories: Seminar, Deliberation, Social, UX, Procedure, Imaginative, Other.\n",
      "Here are some annotated examples:\n",
      "Text: 'I agree' - Category: Procedure\n",
      "Text: 'I want to believe the tiger was behind the door because the princess was semi-barbaric but she was also filled with despair and jealousy.  The green eyed monster.. gets you every time...so she knows she has lost him, but she doesn't have to let the Lady have him.' - Category: Procedure\n",
      "Text: 'As for the second part, I'm not sure if the King would carry out the same punishment for his daughter as he would the commoners. However, he would definitely think of another way to punish her that would consist of a clever, yet barbaric twist for her to prove her loyalty and worth.' - Category: Procedure\n",
      "Text: 'Hi everyone! I think what happens next is that the princess let her lover marry the woman. The reason why I think she would do that is because she loves the man (as they had made each other the center of each others universe) and she would rather see him alive then feel guilty that she is the reason why he dies (she had nightmares of her lover being killed by the tiger). The king represent determinism and barbarism by having chance dictate one's choice (which he had demonstrated in the arena.)  The princess represented free will and progressivism because she actively went out of her way to know which door held which. I do not think a good lover will put harm's way to their love ones. The princess lost the man regardless of which door she choose but at least she can fulfill her role as a lover to never put harms way in his direction and not let the barbaric nature from her father's bloodline to overcome her moral compass.' - Category: Procedure\n",
      "Text: 'I kind of think that even though she is angry and jealous, she would ultimately save him. ' - Category: Procedure\n",
      "Text: 'Good job ladies. Thank you both.' - Category: Imaginative\n",
      "Text: 'Thanks for hopping on for a little bit! I hope you both have a great rest of this semester!' - Category: Imaginative\n",
      "Text: 'Okay!' - Category: Imaginative\n",
      "Text: 'lol ' - Category: Imaginative\n",
      "Text: 'Goodnight!' - Category: Imaginative\n",
      "Text: 'Yeah I put questions, I'll refresh and try again' - Category: Other\n",
      "Text: 'So I don't know. ' - Category: Other\n",
      "Text: 'Which browser did you use?' - Category: Other\n",
      "Text: 'then click submit' - Category: Other\n",
      "Text: 'Perhaps the top of this page (where we type and send messages) is for planning and the bottom (open white area) is for writing an end to the story? ' - Category: Other\n",
      "Text: 'I think you are correct, Ashley. ' - Category: Seminar\n",
      "Text: 'Did you guys get the final question' - Category: Seminar\n",
      "Text: 'If you would like, we can leave both our answers and your ending. That way we have both options covered. But if you'd rather not that's okay too.' - Category: Seminar\n",
      "Text: 'Also feel free to add anything to them if you would like.' - Category: Seminar\n",
      "Text: 'Yes, I think so. We were discussing if we write it like answers or finish the story? Thoughts?' - Category: Seminar\n",
      "Text: 'SUBMITTED' - Category: UX\n",
      "Text: 'Dr. Austin said have fun with it, and it is fun to ponder what might happen in the story. I think the main reason for setting a time to discuss it at the same time would be to test the collaborative software, using the box below instead of this one. I believe we could all write in it at the same time and see each other typing and change each other's words until we all agree we are done with our assessment. If we are able to do that, we might find there are unexpected positives or negatives to the collaboration process or system that we can only otherwise surmise. As you say, we've all responded to the prompts, so what we say doesn't matter that much, so all we'd need is a few minutes to see how using the box works. So if you want to try meeting, I could do Wednesday any time of day. Just set a time and I'll log on then. Thanks.' - Category: UX\n",
      "Text: 'Do you see what I typed in the box below?' - Category: UX\n",
      "Text: 'I'm also in LIS6303!' - Category: UX\n",
      "Text: 'I just replied to the email, but yes\" I can meet back here tomorrow (Tues. at 8pm). \"See\" you all then!\"' - Category: UX\n",
      "Text: 'Ha ha, maybe!' - Category: Deliberation\n",
      "Text: 'I think I'd find it easier to move on and live if he was still alive.' - Category: Deliberation\n",
      "Text: 'I mean there are other guys out there after all.' - Category: Deliberation\n",
      "Text: 'I agree with that so much! ' - Category: Deliberation\n",
      "Text: 'Do you think that the king would be tempted to do the same thing she did, though, and find out which door was which?' - Category: Deliberation\n",
      "Text: 's' - Category: Social\n",
      "Text: 'ha\"' - Category: Social\n",
      "Text: 'uwgyeu' - Category: Social\n",
      "Text: 'darla' - Category: Social\n",
      "Text: 'mor' - Category: Social\n",
      "Text: 'Oooo I have another idea! What if the princess sends the man to the tiger and right out tells her father she did it and wants a trial. Then because he loves her he begs her to choose the door with the young man he picks for her, but she chooses the tiger.' - Category: Social\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(prompt)\n",
    "print(\"Generated Text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(prompt):\n",
    "    generated_text = generate_text(prompt)\n",
    "    # Extract the predicted category from the generated text\n",
    "    return generated_text.split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_df, all_examples):\n",
    "    predictions = []\n",
    "    for index, row in test_df.iterrows(): \n",
    "        prompt = create_prompt(row['text'], all_examples)\n",
    "        predicted_label = predict_category(prompt)\n",
    "        predictions.append(predicted_label)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = test_df['label'].astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predicted_labels, actual_labels):\n",
    "    correct_count = sum(p == labelToCategory[a] for p, a in zip(predicted_labels, actual_labels))\n",
    "    accuracy = correct_count / len(actual_labels)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccb37c1202e40e184035222d0f900a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb8c71cd2f9464e98d01df19b25c330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c38cf366ce49758add6567159cdd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa9b7586d28498ab1e8707658e1eafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d122d5da1254684bb329378a6e794ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f3f144f4574d359b660a360eb218fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62bc831ad55422b89131848148de89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1606458/3720603788.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_data['cluster_label'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT embeddings with Kmeans representatives accuracy: 22.83%\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = evaluate_model(test_df, BERTEmbbedingsKMeans())\n",
    "accuracy = calculate_accuracy(predicted_labels, actual_labels)\n",
    "print(f\"BERT embeddings with Kmeans representatives accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b7207a5b4544acbbffadc399efb8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6285dac6f014ace981ec49f4db453b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfdecc325424eabbd8db022f86f3e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ef86d8fb974305b265e0d2b91bccca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b997fba0ed471f86d9582112a32395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6de86e536ec4e15b9a2da491f94e2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6676e30180a4197a23f45ff7e902be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT embeddings with hierachical clustering representatives accuracy: 31.52%\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = evaluate_model(test_df, BERTEmbeddingsHC())\n",
    "accuracy = calculate_accuracy(predicted_labels, actual_labels)\n",
    "print(f\"BERT embeddings with hierachical clustering representatives accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF with Kmeans representatives accuracy: 29.35%\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = evaluate_model(test_df, tfidf_KMeans())\n",
    "accuracy = calculate_accuracy(predicted_labels, actual_labels)\n",
    "print(f\"TF-IDF with Kmeans representatives accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
